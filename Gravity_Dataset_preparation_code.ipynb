{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda89bcf-5646-4d2a-928f-c21e248a1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered rows: 74\n",
      "Saved filtered dataset to: gravity_irl_uk_clean1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/Users/gouthamjekkula/Desktop/Gravity_V202211.csv\" \n",
    "chunksize = 500_000\n",
    "\n",
    "filtered_chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):\n",
    "    filtered = chunk[\n",
    "        (chunk['iso3_o'] == 'IRL') & (chunk['iso3_d'] == 'GBR')\n",
    "    ]\n",
    "    if not filtered.empty:\n",
    "        filtered_chunks.append(filtered)\n",
    "\n",
    "gravity_irl_uk = pd.concat(filtered_chunks)\n",
    "print(f\"Filtered rows: {gravity_irl_uk.shape[0]}\")\n",
    "\n",
    "# Keep country_id columns for traceability\n",
    "cols_to_keep = [\n",
    "    'year', \n",
    "    'country_id_o', 'country_id_d', 'iso3_o', 'iso3_d',\n",
    "    'distw_harmonic', 'distw_arithmetic', 'dist',\n",
    "    'contig', 'comlang_off', 'comcol', 'col45',\n",
    "    'gdp_o', 'gdp_d', 'gdpcap_o', 'gdpcap_d',\n",
    "    'pop_o', 'pop_d', 'rta_coverage', 'rta_type'\n",
    "]\n",
    "\n",
    "gravity_irl_uk_clean = gravity_irl_uk[cols_to_keep]\n",
    "\n",
    "# Save filtered file\n",
    "output_file = \"gravity_irl_uk_clean1.xlsx\"\n",
    "gravity_irl_uk_clean.to_excel(output_file, index=False)\n",
    "print(f\"Saved filtered dataset to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49e3f12-6620-425a-84ea-a63de764ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ireland periods: 121 rows, sample -> ['1995Q1', '1995Q2', '1995Q3']\n",
      "UK periods: 121 rows, sample -> ['1995Q1', '1995Q2', '1995Q3']\n",
      "[OK] Saved → Ireland_United Kingdom_GDP1.xlsx\n",
      "Period Ireland  Ireland GDP values United Kingdom  United Kingdom Values   Unit value\n",
      "1995Q1 Ireland               13334 United Kingdom              242042.12 Euro million\n",
      "1995Q2 Ireland               13648 United Kingdom              244467.68 Euro million\n",
      "1995Q3 Ireland               13689 United Kingdom              248954.56 Euro million\n",
      "1995Q4 Ireland               14053 United Kingdom              252675.84 Euro million\n",
      "1996Q1 Ireland               14643 United Kingdom              256862.28 Euro million\n",
      "1996Q2 Ireland               14989 United Kingdom              262376.92 Euro million\n",
      "1996Q3 Ireland               14920 United Kingdom              266697.92 Euro million\n",
      "1996Q4 Ireland               15503 United Kingdom              269654.76 Euro million\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "IE_FILE = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/Ireland Current Gdp Values.xlsx\")  # Ireland file (Unpivoted sheet)\n",
    "UK_FILE = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/United Kingdom Current GDP values.xlsx\")       # UK file\n",
    "GBP_TO_EUR = 1.16\n",
    "OUT_FILE = Path(\"Ireland_United Kingdom_GDP1.xlsx\")\n",
    "def normalize_period(s):\n",
    "    \"\"\"Return 'YYYYQx' (no spaces, uppercase) from variants like '1995Q1', '1995 Q1', etc.\"\"\"\n",
    "    s = str(s).strip().upper()\n",
    "    m = re.match(r\"^\\s*(\\d{4})\\s*Q\\s*([1-4])\\s*$\", s.replace(\"Q\", \" Q \"))\n",
    "    if m:\n",
    "        return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # also allow '1995Q1' directly\n",
    "    m = re.match(r\"^\\s*(\\d{4})Q([1-4])\\s*$\", s)\n",
    "    if m:\n",
    "        return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "# IRELAND \n",
    "ie = pd.read_excel(IE_FILE, sheet_name=\"Unpivoted\")\n",
    "ie.columns = [str(c).strip() for c in ie.columns]\n",
    "\n",
    "# Keep the exact series shown in your screenshot\n",
    "label_col = \"Statistic Label\" if \"Statistic Label\" in ie.columns else \"STATISTIC LABEL\"\n",
    "val_col   = \"VALUE\" if \"VALUE\" in ie.columns else \"Value\"\n",
    "q_col     = \"Quarter\" if \"Quarter\" in ie.columns else \"QUARTER\"\n",
    "\n",
    "ie = ie[ie[label_col].str.strip().eq(\"GDP at Current Market Prices (Seasonally Adjusted)\")].copy()\n",
    "ie[\"Period\"] = ie[q_col].map(normalize_period)\n",
    "ie[\"Ireland GDP values\"] = pd.to_numeric(ie[val_col], errors=\"coerce\")\n",
    "ie = ie[[\"Period\", \"Ireland GDP values\"]].dropna(subset=[\"Period\", \"Ireland GDP values\"])\n",
    "ie[\"Ireland\"] = \"Ireland\"\n",
    "\n",
    "# Diagnostics\n",
    "print(f\"Ireland periods: {ie['Period'].nunique()} rows, sample ->\", ie['Period'].head(3).tolist())\n",
    "\n",
    "#UNITED KINGDOM \n",
    "# autodetected the header row containing 'Quarterly' and 'GDP Values'\n",
    "raw = pd.read_excel(UK_FILE, header=None)\n",
    "header_row = None\n",
    "for i in range(min(30, len(raw))):  # search first 30 rows\n",
    "    row_vals = [str(x).strip() for x in raw.iloc[i].tolist()]\n",
    "    if (\"Quarterly\" in row_vals) and (\"GDP Values\" in row_vals):\n",
    "        header_row = i\n",
    "        break\n",
    "\n",
    "if header_row is None:\n",
    "    # Fallback: from your screenshot it looked like headers start at Excel row 10 -> zero-based 9\n",
    "    header_row = 9\n",
    "\n",
    "uk = pd.read_excel(UK_FILE, header=header_row)\n",
    "uk.columns = [str(c).strip() for c in uk.columns]\n",
    "\n",
    "# To Make sure expected columns exist; else take first two columns and rename\n",
    "if not {\"Quarterly\", \"GDP Values\"}.issubset(set(uk.columns)):\n",
    "    uk = uk.iloc[:, :2].copy()\n",
    "    uk.columns = [\"Quarterly\", \"GDP Values\"]\n",
    "\n",
    "uk[\"Period\"] = uk[\"Quarterly\"].map(normalize_period)\n",
    "uk[\"United Kingdom Values\"] = pd.to_numeric(uk[\"GDP Values\"], errors=\"coerce\") * GBP_TO_EUR\n",
    "uk = uk[[\"Period\", \"United Kingdom Values\"]].dropna(subset=[\"Period\", \"United Kingdom Values\"])\n",
    "uk[\"United Kingdom\"] = \"United Kingdom\"\n",
    "\n",
    "# Diagnostics\n",
    "print(f\"UK periods: {uk['Period'].nunique()} rows, sample ->\", uk['Period'].head(3).tolist())\n",
    "\n",
    "# ---------- MERGE ----------\n",
    "combined = (ie.merge(uk, on=\"Period\", how=\"inner\")\n",
    "              .sort_values(\"Period\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "# If it comes out empty, show why\n",
    "if combined.empty:\n",
    "    ie_set = set(ie[\"Period\"])\n",
    "    uk_set = set(uk[\"Period\"])\n",
    "    only_ie = sorted(list(ie_set - uk_set))[:5]\n",
    "    only_uk = sorted(list(uk_set - ie_set))[:5]\n",
    "    print(\"Merged result is empty. Example periods only in Ireland:\", only_ie)\n",
    "    print(\"Example periods only in UK:\", only_uk)\n",
    "\n",
    "# Final columns\n",
    "combined[\"Unit value\"] = \"Euro million\"\n",
    "combined[\"Ireland\"] = \"Ireland\"                # ensure present\n",
    "combined[\"United Kingdom\"] = \"United Kingdom\"  # ensure present\n",
    "combined = combined[[\n",
    "    \"Period\",\n",
    "    \"Ireland\",\n",
    "    \"Ireland GDP values\",\n",
    "    \"United Kingdom\",\n",
    "    \"United Kingdom Values\",\n",
    "    \"Unit value\"\n",
    "]]\n",
    "\n",
    "# Save\n",
    "combined.to_excel(OUT_FILE, index=False)\n",
    "print(f\"[OK] Saved → {OUT_FILE}\")\n",
    "print(combined.head(8).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c509185-5827-4aa6-ae52-afed7ce504c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved real GDP dataset → Ireland_United Kingdom_Real_GDP1.xlsx\n",
      "Period  Ireland (Nominal, €m)  Ireland (Real, €m, 2015=100)  United Kingdom (Nominal, €m)  United Kingdom (Real, €m, 2015=100)\n",
      "1995Q1                  13334                  22207.465571                     242042.12                        345035.709797\n",
      "1995Q2                  13648                  22730.425237                     244467.68                        348493.392353\n",
      "1995Q3                  13689                  22798.709779                     248954.56                        354889.526322\n",
      "1995Q4                  14053                  23404.943278                     252675.84                        360194.282726\n",
      "1996Q1                  14643                  24387.574498                     256862.28                        366162.133681\n",
      "1996Q2                  14989                  24963.829417                     262376.92                        374023.359349\n",
      "1996Q3                  14920                  24848.911528                     266697.92                        380183.028179\n",
      "1996Q4                  15503                  25819.884412                     269654.76                        384398.060621\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Input Files\n",
    "NOMINAL_FILE = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/Ireland_United Kingdom_GDP.xlsx\")\n",
    "IE_DEFLATOR  = Path(\"/Users/gouthamjekkula/Downloads/alfredgraph.xlsx\")\n",
    "UK_DEFLATOR  = Path(\"/Users/gouthamjekkula/Downloads/GBRGDPDEFQISMEI.xlsx\")\n",
    "OUT_FILE     = Path(\"Ireland_United Kingdom_Real_GDP1.xlsx\")\n",
    "\n",
    "def to_period_quarter(dt):\n",
    "    \"\"\"Map datetime to YYYYQn.\"\"\"\n",
    "    y = dt.year\n",
    "    q = (dt.month - 1) // 3 + 1\n",
    "    return f\"{y}Q{q}\"\n",
    "\n",
    "def normalize_period_any(x):\n",
    "    \"\"\"Convert various formats to YYYYQn.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if hasattr(x, \"year\"):\n",
    "        return to_period_quarter(x)\n",
    "    s = str(x).strip().upper()\n",
    "    m = re.match(r\"^(\\d{4})\\s*Q\\s*([1-4])$\", s.replace(\"Q\",\" Q \"))\n",
    "    if m:\n",
    "        return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    m = re.match(r\"^Q\\s*([1-4])\\s*(\\d{4})$\", s)\n",
    "    if m:\n",
    "        return f\"{m.group(2)}Q{m.group(1)}\"\n",
    "    try:\n",
    "        dt = pd.to_datetime(s, errors=\"raise\")\n",
    "        return to_period_quarter(dt)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def read_alfred_quarterly_latest(filepath, series_colname):\n",
    "    \"\"\"Read ALFRED/FRED quarterly sheet and return Period + latest value.\"\"\"\n",
    "    df = pd.read_excel(filepath, sheet_name=\"Quarterly\", header=0)\n",
    "    date_col = df.columns[0]\n",
    "    if series_colname not in df.columns:\n",
    "        raise ValueError(f\"Series '{series_colname}' not found in {filepath.name}\")\n",
    "    out = pd.DataFrame({\n",
    "        \"Period\": df[date_col].apply(normalize_period_any),\n",
    "        \"value\": pd.to_numeric(df[series_colname], errors=\"coerce\")\n",
    "    }).dropna(subset=[\"Period\",\"value\"])\n",
    "    return out.sort_values(\"Period\")\n",
    "\n",
    "#1) Nominal GDP \n",
    "nom = pd.read_excel(NOMINAL_FILE)\n",
    "nom.columns = [str(c).strip() for c in nom.columns]\n",
    "nom[\"Period\"] = nom[\"Period\"].apply(normalize_period_any)\n",
    "nom = nom.rename(columns={\n",
    "    \"Ireland GDP values\": \"IE_nominal_eur_m\",\n",
    "    \"United Kingdom Values\": \"UK_nominal_eur_m\"\n",
    "})[[\"Period\",\"IE_nominal_eur_m\",\"UK_nominal_eur_m\"]]\n",
    "\n",
    "# 2) Ireland deflator (2015=100)\n",
    "#Ireland deflator (2015=100) — explicit column \n",
    "# Uses the most recent vintage you showed: IRLGDPDEFQISMEI_20231209\n",
    "ie_raw = pd.read_excel(\"alfredgraph.xlsx\", sheet_name=\"Quarterly\")\n",
    "\n",
    "# Normalize to YYYYQn \n",
    "ie_raw[\"Period\"] = ie_raw[\"observation_date\"].apply(normalize_period_any)\n",
    "\n",
    "# Pick the exact column; fall back to the rightmost series if the name changes\n",
    "COL_IRL = \"IRLGDPDEFQISMEI_20231209\"\n",
    "if COL_IRL not in ie_raw.columns:\n",
    "    # fallback: take the last non-date column\n",
    "    cand_cols = [c for c in ie_raw.columns if c != \"observation_date\"]\n",
    "    COL_IRL = cand_cols[-1]\n",
    "\n",
    "ie_def = (ie_raw[[\"Period\", COL_IRL]]\n",
    "          .rename(columns={COL_IRL: \"IE_deflator_2015=100\"})\n",
    "          .dropna(subset=[\"Period\", \"IE_deflator_2015=100\"])\n",
    "          .sort_values(\"Period\")\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "#3) UK deflator (2015=100)\n",
    "uk_def = read_alfred_quarterly_latest(UK_DEFLATOR, series_colname=\"GBRGDPDEFQISMEI\")\n",
    "uk_def = uk_def.rename(columns={\"value\": \"UK_deflator_2015=100\"})\n",
    "\n",
    "# 4) Merge all\n",
    "df = (nom.merge(ie_def, on=\"Period\", how=\"left\")\n",
    "         .merge(uk_def, on=\"Period\", how=\"left\")\n",
    "         .sort_values(\"Period\")\n",
    "         .reset_index(drop=True))\n",
    "\n",
    "# 5) Fill missing deflators (e.g., 2024–2025)\n",
    "for col in [\"IE_deflator_2015=100\",\"UK_deflator_2015=100\"]:\n",
    "    df[col] = df[col].astype(float).ffill().bfill()\n",
    "\n",
    "# 6) Convert nominal → real (2015 prices, €m) \n",
    "df[\"Ireland (Real, €m, 2015=100)\"] = (df[\"IE_nominal_eur_m\"] / df[\"IE_deflator_2015=100\"]) * 100.0\n",
    "df[\"United Kingdom (Real, €m, 2015=100)\"] = (df[\"UK_nominal_eur_m\"] / df[\"UK_deflator_2015=100\"]) * 100.0\n",
    "\n",
    "#7) Save output \n",
    "out = df[[\n",
    "    \"Period\",\n",
    "    \"IE_nominal_eur_m\",\n",
    "    \"Ireland (Real, €m, 2015=100)\",\n",
    "    \"UK_nominal_eur_m\",\n",
    "    \"United Kingdom (Real, €m, 2015=100)\"\n",
    "]].rename(columns={\n",
    "    \"IE_nominal_eur_m\": \"Ireland (Nominal, €m)\",\n",
    "    \"UK_nominal_eur_m\": \"United Kingdom (Nominal, €m)\"\n",
    "})\n",
    "\n",
    "out.to_excel(OUT_FILE, index=False)\n",
    "print(f\"[OK] Saved real GDP dataset → {OUT_FILE}\")\n",
    "print(out.head(8).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3289d6-12a9-44a7-824b-c93b870c2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataset saved: GRAVITY_GDP_IE_UK_2015_2023_MONTHLY.xlsx\n",
      "Rows: 108\n",
      "Cols: ['Date', 'year', 'country_id_o', 'country_id_d', 'iso3_o', 'iso3_d', 'distw_harmonic', 'distw_arithmetic', 'dist', 'contig', 'comlang_off', 'comcol', 'col45', 'gdp_o', 'gdp_d', 'gdpcap_o', 'gdpcap_d', 'pop_o', 'pop_d', 'rta_coverage', 'rta_type', 'GDP_IE_real_eur_m', 'GDP_UK_real_eur_m']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# FILE PATHS\n",
    "GRAVITY_XLSX = \"/Users/gouthamjekkula/Desktop/Thesis Folder/gravity_irl_uk_clean1.xlsx\"\n",
    "GDP_XLSX     = \"/Users/gouthamjekkula/Desktop/Thesis Folder/Ireland_United Kingdom_Real_GDP1.xlsx\"\n",
    "OUT_XLSX     = \"GRAVITY_GDP_IE_UK_2015_2023_MONTHLY.xlsx\"\n",
    "\n",
    "\n",
    "# DATE WINDOW\n",
    "START = pd.Timestamp(\"2015-01-01\")\n",
    "END   = pd.Timestamp(\"2023-12-01\")\n",
    "\n",
    "\n",
    "# 1) LOAD GRAVITY AND EXPAND TO MONTHLY\n",
    "\n",
    "g = pd.read_excel(GRAVITY_XLSX)\n",
    "\n",
    "# IRL-GBR only\n",
    "g = g[(g[\"iso3_o\"].isin([\"IRL\",\"GBR\"])) & (g[\"iso3_d\"].isin([\"IRL\",\"GBR\"]))]\n",
    "\n",
    "# Expand YEAR -> 12 months\n",
    "def expand_year_row(row):\n",
    "    y = int(row[\"year\"])\n",
    "    months = pd.date_range(f\"{y}-01-01\", periods=12, freq=\"MS\")\n",
    "    rep = pd.DataFrame({col: row[col] for col in g.columns}, index=months)\n",
    "    rep.index.name = \"Date\"\n",
    "    return rep.reset_index()\n",
    "\n",
    "g_monthly = pd.concat([expand_year_row(r) for _, r in g.iterrows()], ignore_index=True)\n",
    "\n",
    "# Filter 2015-2021 (since gravity stops at 2021)\n",
    "g_monthly[\"Date\"] = pd.to_datetime(g_monthly[\"Date\"])\n",
    "g_monthly = g_monthly[(g_monthly[\"Date\"] >= START) & (g_monthly[\"Date\"] <= pd.Timestamp(\"2021-12-01\"))]\n",
    "\n",
    "\n",
    "# 2) CREATE EXTENSION 2022–2023 (using last available row as template)\n",
    "\n",
    "last_row = g_monthly[g_monthly[\"year\"] == 2021].iloc[0].copy()\n",
    "\n",
    "months_2022_2023 = pd.date_range(\"2022-01-01\", \"2023-12-01\", freq=\"MS\")\n",
    "\n",
    "rows = []\n",
    "for m in months_2022_2023:\n",
    "    new_row = last_row.copy()\n",
    "    new_row[\"year\"] = m.year\n",
    "    new_row[\"Date\"] = m\n",
    "    rows.append(new_row)\n",
    "\n",
    "g_ext = pd.DataFrame(rows)\n",
    "\n",
    "# Combine with 2015–2021 monthly\n",
    "g_full = pd.concat([g_monthly, g_ext], ignore_index=True)\n",
    "\n",
    "# 3) LOAD GDP & UPSAMPLE QUARTERLY → MONTHLY\n",
    "\n",
    "gdpr = pd.read_excel(GDP_XLSX)\n",
    "\n",
    "IE_REAL_COL  = \"Ireland (Real, €m, 2015=100)\"\n",
    "UK_REAL_COL  = \"United Kingdom (Real, €m, 2015=100)\"\n",
    "PERIOD_COL   = \"Period\"\n",
    "\n",
    "def period_to_months(p):\n",
    "    s = str(p).strip().upper().replace(\" \", \"\")\n",
    "    if \"Q\" in s and len(s) >= 6:\n",
    "        year = int(s[:4]); q = int(s[-1])\n",
    "        start_month = {1:1, 2:4, 3:7, 4:10}[q]\n",
    "        return pd.date_range(pd.Timestamp(year, start_month, 1), periods=3, freq=\"MS\")\n",
    "    if \"-\" in s:\n",
    "        y, m = map(int, s.split(\"-\")[:2])\n",
    "        return pd.DatetimeIndex([pd.Timestamp(y, m, 1)])\n",
    "    if s.isdigit() and len(s) == 4:\n",
    "        y = int(s)\n",
    "        return pd.date_range(pd.Timestamp(y, 1, 1), periods=12, freq=\"MS\")\n",
    "    raise ValueError(f\"Unrecognized Period: {p}\")\n",
    "\n",
    "rows = []\n",
    "for _, r in gdpr.iterrows():\n",
    "    months = period_to_months(r[PERIOD_COL])\n",
    "    df = pd.DataFrame({\n",
    "        \"Date\": months,\n",
    "        \"GDP_IE_real_eur_m\": r[IE_REAL_COL],\n",
    "        \"GDP_UK_real_eur_m\": r[UK_REAL_COL]\n",
    "    })\n",
    "    rows.append(df)\n",
    "\n",
    "gdp_m = pd.concat(rows, ignore_index=True)\n",
    "gdp_m = gdp_m[(gdp_m[\"Date\"] >= START) & (gdp_m[\"Date\"] <= END)]\n",
    "gdp_m = gdp_m.groupby(\"Date\", as_index=False).last()\n",
    "\n",
    "# 4) MERGE GRAVITY + GDP\n",
    "merged = g_full.merge(gdp_m, on=\"Date\", how=\"left\")\n",
    "\n",
    "\n",
    "# 5) OVERWRITE WITH EXTERNAL DATA (2015–2023 monthly series)\n",
    "# rta_coverage values (length = 108 months)\n",
    "rta_coverage_vals = [\n",
    "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3\n",
    "]\n",
    "\n",
    "rta_type_vals = [\n",
    "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5\n",
    "]\n",
    "\n",
    "# pop_o and pop_d values (108 each)\n",
    "pop_o_vals = [4701957]*12 + [4762722]*12 + [4827445]*12 + [4898022]*12 + [4976456]*12 + [5039747]*12 + [5110585]*12 + [5212836]*12 + [5307600]*12\n",
    "pop_d_vals = [65088000]*12 + [65607000]*12 + [65966000]*12 + [66289000]*12 + [66631000]*12 + [66744000]*12 + [66984000]*12 + [67604000]*12 + [68492000]*12\n",
    "\n",
    "#Assign to merged\n",
    "merged = merged.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "merged[\"rta_coverage\"] = rta_coverage_vals\n",
    "merged[\"rta_type\"]     = rta_type_vals\n",
    "merged[\"pop_o\"]        = pop_o_vals\n",
    "merged[\"pop_d\"]        = pop_d_vals\n",
    "\n",
    "# 6) SAVE\n",
    "merged.to_excel(OUT_XLSX, index=False)\n",
    "print(\"Final dataset saved:\", OUT_XLSX)\n",
    "print(\"Rows:\", len(merged))\n",
    "print(\"Cols:\", list(merged.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eb66693-1ccd-41f8-90a7-d06bd0e52215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GDP per capita summary (Euro/person):\n",
      "          gdpcap_o   gdpcap_d\n",
      "min   13993.610000  6995.6800\n",
      "max   22859.150000  9132.2400\n",
      "mean  17928.290278  8740.6425\n",
      "\n",
      "✅ Saved: PPML_Gravity1.xlsx \n",
      "Rows: 108  |  Columns: 23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "INFILE  = \"/Users/gouthamjekkula/Desktop/Thesis Folder/GRAVITY_GDP_IE_UK_2015_2023_MONTHLY.xlsx\"\n",
    "OUT_XLS = \"PPML_Gravity1.xlsx\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_excel(INFILE)\n",
    "if \"Date\" in df.columns:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "#Check columns\n",
    "expected_cols = [\"GDP_IE_real_eur_m\", \"GDP_UK_real_eur_m\", \"pop_o\", \"pop_d\"]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing column(s): {missing}\")\n",
    "\n",
    "# Clean/guard: make sure populations > 0 to avoid division errors\n",
    "for c in [\"pop_o\", \"pop_d\"]:\n",
    "    if (df[c] <= 0).any():\n",
    "        raise ValueError(f\"Non‑positive values found in {c}. Fix before proceeding.\")\n",
    "\n",
    "# Calculate GDP per capita (Euro/person)\n",
    "\n",
    "df[\"gdpcap_o\"] = (df[\"GDP_IE_real_eur_m\"] * 1_000_000) / df[\"pop_o\"]\n",
    "df[\"gdpcap_d\"] = (df[\"GDP_UK_real_eur_m\"] * 1_000_000) / df[\"pop_d\"]\n",
    "\n",
    "# Optional: round for readability (keep full precision if you prefer)\n",
    "df[\"gdpcap_o\"] = df[\"gdpcap_o\"].round(2)\n",
    "df[\"gdpcap_d\"] = df[\"gdpcap_d\"].round(2)\n",
    "\n",
    "# Quick diagnostics\n",
    "stats = df[[\"gdpcap_o\", \"gdpcap_d\"]].agg([\"min\", \"max\", \"mean\"])\n",
    "print(\"\\nGDP per capita summary (Euro/person):\")\n",
    "print(stats)\n",
    "\n",
    "# Flag unrealistic values\n",
    "for col in [\"gdpcap_o\", \"gdpcap_d\"]:\n",
    "    bad = df[(df[col] < 5_000) | (df[col] > 150_000)]\n",
    "    if not bad.empty:\n",
    "        print(f\"\\n⚠ Warning: {len(bad)} rows in {col} outside expected range [5k, 150k].\")\n",
    "        print(bad[[\"Date\", \"iso3_o\", \"iso3_d\", col]].head(10).to_string(index=False))\n",
    "\n",
    "#Save\n",
    "df.to_excel(OUT_XLS, index=False)\n",
    "print(f\"\\nSaved: {OUT_XLS} \")\n",
    "print(f\"Rows: {len(df):,}  |  Columns: {len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9dba315-17e8-432e-bd9a-f73cb1bf6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved → Tariffs_2015_2023_Monthly_Sectors_Wide_AHS.xlsx\n",
      "Rows (wide): 108 | Cols (wide): 22\n",
      " Reporter Name Partner Name       Date  Tariff Year  Pharma_WeightedAvg  Pharma_SimpleAvg  Pharma_Imports_EuroM  Agriculture_WeightedAvg  Agriculture_SimpleAvg  Agriculture_Imports_EuroM  Beverages_WeightedAvg  Beverages_SimpleAvg  Beverages_Imports_EuroM  Dairy_WeightedAvg  Dairy_SimpleAvg  Dairy_Imports_EuroM  Meat_WeightedAvg  Meat_SimpleAvg  Meat_Imports_EuroM  Vegetables_WeightedAvg  Vegetables_SimpleAvg  Vegetables_Imports_EuroM\n",
      "United Kingdom      Ireland 2015-01-01          NaN                 NaN               NaN                   NaN                      NaN                    NaN                        NaN                    NaN                  NaN                      NaN                NaN              NaN                  NaN               NaN             NaN                 NaN                     NaN                   NaN                       NaN\n",
      "United Kingdom      Ireland 2015-02-01          NaN                 NaN               NaN                   NaN                      NaN                    NaN                        NaN                    NaN                  NaN                      NaN                NaN              NaN                  NaN               NaN             NaN                 NaN                     NaN                   NaN                       NaN\n",
      "United Kingdom      Ireland 2015-03-01          NaN                 NaN               NaN                   NaN                      NaN                    NaN                        NaN                    NaN                  NaN                      NaN                NaN              NaN                  NaN               NaN             NaN                 NaN                     NaN                   NaN                       NaN\n",
      "United Kingdom      Ireland 2015-04-01          NaN                 NaN               NaN                   NaN                      NaN                    NaN                        NaN                    NaN                  NaN                      NaN                NaN              NaN                  NaN               NaN             NaN                 NaN                     NaN                   NaN                       NaN\n",
      "United Kingdom      Ireland 2015-05-01          NaN                 NaN               NaN                   NaN                      NaN                    NaN                        NaN                    NaN                  NaN                      NaN                NaN              NaN                  NaN               NaN             NaN                 NaN                     NaN                   NaN                       NaN\n",
      "United Kingdom      Ireland 2015-06-01          NaN                 NaN               NaN                   NaN                      NaN                    NaN                        NaN                    NaN                  NaN                      NaN                NaN              NaN                  NaN               NaN             NaN                 NaN                     NaN                   NaN                       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "IN_FILE  = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/IRL&UK Tariffs.xlsx\")  \n",
    "OUT_WIDE = Path(\"Tariffs_2015_2023_Monthly_Sectors_Wide_AHS.xlsx\")\n",
    "\n",
    "START_YEAR = 2015\n",
    "END_YEAR   = 2023\n",
    "\n",
    "USD_TO_EUR   = 0.93\n",
    "KUSD_TO_MEUR = USD_TO_EUR / 1000.0\n",
    "\n",
    "# Sector mapping tuned to  file’s Product Namme\n",
    "SECTOR_CONTAINS = {\n",
    "    \"Pharma\":       [\"pharma\"],                     \n",
    "    \"Meat\":         [\"meat &\", \"meat and\"],        \n",
    "    \"Dairy\":        [\"dairy\"],                     \n",
    "    \"Beverages\":    [\"beverages\"],\n",
    "    \"Agriculture\": [\n",
    "        \"live animals except fish\",\n",
    "        \"cereals/cereal\",                           \n",
    "        \"vegetables and fruit\",\n",
    "        \"sugar/sugar\",                              \n",
    "        \"coffee/tea/cocoa/spices\",\n",
    "        \"animal feed ex unml cer.\",\n",
    "        \"misc food products\",\n",
    "    ],\n",
    "    \"Vegetables\":   [\"crude anim/veg mater nes\"],   \n",
    "}\n",
    "\n",
    "# mapping to ISO3 for clean joins later\n",
    "ISO3_MAP = {\n",
    "    \"Ireland\": \"IRL\",\n",
    "    \"United Kingdom\": \"GBR\",\n",
    "    \"UK\": \"GBR\",\n",
    "    \"Great Britain\": \"GBR\",\n",
    "    \n",
    "}\n",
    "\n",
    "def year_to_month_starts(year: int):\n",
    "    return pd.date_range(f\"{year}-01-01\", f\"{year}-12-01\", freq=\"MS\")\n",
    "\n",
    "def map_sector(name_lower: str):\n",
    "    for sector, needles in SECTOR_CONTAINS.items():\n",
    "        for needle in needles:\n",
    "            if needle in name_lower:\n",
    "                return sector\n",
    "    return None\n",
    "\n",
    "# 1) Read\n",
    "tar = pd.read_excel(IN_FILE)\n",
    "tar.columns = [str(c).strip() for c in tar.columns]\n",
    "\n",
    "need = [\n",
    "    \"Tariff Year\", \"Product Name\", \"Reporter Name\", \"Partner Name\",\n",
    "    \"DutyType\", \"Weighted Average\", \"Simple Average\", \"Imports Value in 1000 USD\"\n",
    "]\n",
    "missing = [c for c in need if c not in tar.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in {IN_FILE.name}: {missing}\")\n",
    "\n",
    "# 2) For AHS only (applied rates)\n",
    "tar = tar[tar[\"DutyType\"].astype(str).str.upper().eq(\"AHS\")].copy()\n",
    "\n",
    "# 3) Clean types & restrict years (2015–2023)\n",
    "tar[\"Tariff Year\"] = pd.to_numeric(tar[\"Tariff Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "for c in [\"Weighted Average\", \"Simple Average\", \"Imports Value in 1000 USD\"]:\n",
    "    tar[c] = pd.to_numeric(tar[c], errors=\"coerce\")\n",
    "\n",
    "tar = tar[tar[\"Tariff Year\"].between(START_YEAR, END_YEAR, inclusive=\"both\")].copy()\n",
    "\n",
    "# 4) Map to six sectors\n",
    "plower = tar[\"Product Name\"].astype(str).str.lower()\n",
    "tar[\"Sector\"] = plower.apply(map_sector)\n",
    "tar = tar.dropna(subset=[\"Sector\", \"Tariff Year\"]).copy()\n",
    "\n",
    "# 5) Aggregate by (Year × Reporter × Partner × Sector) with imports-weighted average\n",
    "value_cols = [\"Weighted Average\", \"Simple Average\", \"Imports Value in 1000 USD\"]\n",
    "\n",
    "def agg_sector(g):\n",
    "    w = g[\"Imports Value in 1000 USD\"].fillna(0)\n",
    "    x = g[\"Weighted Average\"]\n",
    "    if (w > 0).any() and x.notna().any():\n",
    "        weighted_avg = np.average(x.fillna(0), weights=w)\n",
    "    else:\n",
    "        weighted_avg = x.mean()\n",
    "    simple_avg = g[\"Simple Average\"].mean()\n",
    "    imports_sum_kusd = g[\"Imports Value in 1000 USD\"].sum(min_count=1)\n",
    "    return pd.Series({\n",
    "        \"WeightedAvg\": weighted_avg,\n",
    "        \"SimpleAvg\": simple_avg,\n",
    "        \"Imports_EuroM\": imports_sum_kusd * KUSD_TO_MEUR\n",
    "    })\n",
    "\n",
    "group_cols = [\"Tariff Year\",\"Reporter Name\",\"Partner Name\",\"Sector\"]\n",
    "agg = (tar.groupby(group_cols, dropna=False, observed=False)[value_cols]\n",
    "         .apply(agg_sector)\n",
    "         .reset_index())\n",
    "\n",
    "# If nothing matched (unlikely), It write's empty template for 2015–2023 and exit\n",
    "if agg.empty:\n",
    "    all_months = pd.date_range(f\"{START_YEAR}-01-01\", f\"{END_YEAR}-12-01\", freq=\"MS\")\n",
    "    cols = [\"Date\",\"Reporter Name\",\"Partner Name\"]\n",
    "    for s in [\"Pharma\",\"Agriculture\",\"Beverages\",\"Dairy\",\"Meat\",\"Vegetables\"]:\n",
    "        cols += [f\"{s}_WeightedAvg\", f\"{s}_SimpleAvg\", f\"{s}_Imports_EuroM\"]\n",
    "    out = pd.DataFrame({\"Date\": all_months})\n",
    "    for c in cols:\n",
    "        if c != \"Date\":\n",
    "            out[c] = np.nan\n",
    "    out.to_excel(OUT_WIDE, index=False)\n",
    "    print(f\"[WARN] No AHS rows matched; wrote empty template → {OUT_WIDE}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# 6) Pivot to wide by sector for each (Year/Reporter/Partner)\n",
    "w_weighted = (agg.pivot(index=[\"Tariff Year\",\"Reporter Name\",\"Partner Name\"],\n",
    "                        columns=\"Sector\", values=\"WeightedAvg\")\n",
    "                .add_suffix(\"_WeightedAvg\"))\n",
    "w_simple   = (agg.pivot(index=[\"Tariff Year\",\"Reporter Name\",\"Partner Name\"],\n",
    "                        columns=\"Sector\", values=\"SimpleAvg\")\n",
    "                .add_suffix(\"_SimpleAvg\"))\n",
    "w_imports  = (agg.pivot(index=[\"Tariff Year\",\"Reporter Name\",\"Partner Name\"],\n",
    "                        columns=\"Sector\", values=\"Imports_EuroM\")\n",
    "                .add_suffix(\"_Imports_EuroM\"))\n",
    "\n",
    "wide_year = (w_weighted.join(w_simple, how=\"outer\")\n",
    "                        .join(w_imports, how=\"outer\")\n",
    "                        .reset_index())\n",
    "\n",
    "# 7) Ensure all expected sector columns exist\n",
    "expected_cols = []\n",
    "for s in [\"Pharma\",\"Agriculture\",\"Beverages\",\"Dairy\",\"Meat\",\"Vegetables\"]:\n",
    "    expected_cols += [f\"{s}_WeightedAvg\", f\"{s}_SimpleAvg\", f\"{s}_Imports_EuroM\"]\n",
    "for c in expected_cols:\n",
    "    if c not in wide_year.columns:\n",
    "        wide_year[c] = np.nan\n",
    "\n",
    "# 8) Expand each year to 12 months - Date\n",
    "months = pd.DataFrame({\"Month\": range(1, 13)})\n",
    "wide_year[\"Tariff Year\"] = wide_year[\"Tariff Year\"].astype(int)\n",
    "wide_year[\"key\"] = 1; months[\"key\"] = 1\n",
    "monthly = (wide_year.merge(months, on=\"key\", how=\"outer\").drop(columns=\"key\"))\n",
    "monthly[\"Date\"] = pd.to_datetime(dict(year=monthly[\"Tariff Year\"], month=monthly[\"Month\"], day=1))\n",
    "monthly = monthly.drop(columns=[\"Month\"]).sort_values([\"Reporter Name\",\"Partner Name\",\"Date\"])\n",
    "\n",
    "# 9) Build full monthly grid 2015–2023 for all reporter/partner pairs seen\n",
    "pairs = monthly[[\"Reporter Name\",\"Partner Name\"]].drop_duplicates().reset_index(drop=True)\n",
    "all_months = pd.date_range(f\"{START_YEAR}-01-01\", f\"{END_YEAR}-12-01\", freq=\"MS\")\n",
    "full_grid = (pairs.assign(_k=1)\n",
    "                  .merge(pd.DataFrame({\"_k\":1,\"Date\":all_months}), on=\"_k\", how=\"outer\")\n",
    "                  .drop(columns=\"_k\"))\n",
    "\n",
    "# 10) Left‑join observed months (2015–2023) onto full grid\n",
    "keep_cols = [\"Date\",\"Reporter Name\",\"Partner Name\",\"Tariff Year\"] + expected_cols\n",
    "result_wide = (full_grid.merge(monthly[keep_cols], on=[\"Date\",\"Reporter Name\",\"Partner Name\"], how=\"left\")\n",
    "                        .sort_values([\"Reporter Name\",\"Partner Name\",\"Date\"])\n",
    "                        .reset_index(drop=True))\n",
    "\n",
    "\n",
    "\n",
    "result_long = pd.concat(long_rows, ignore_index=True)\n",
    "result_long[\"ReporterISO3\"] = result_long[\"Reporter Name\"].map(to_iso3)\n",
    "result_long[\"PartnerISO3\"]  = result_long[\"Partner Name\"].map(to_iso3)\n",
    "\n",
    "# 12) SAVE\n",
    "result_wide.to_excel(OUT_WIDE, index=False)\n",
    "\n",
    "print(f\"[OK] Saved → {OUT_WIDE}\")\n",
    "print(f\"Rows (wide): {len(result_wide):,} | Cols (wide): {len(result_wide.columns)}\")\n",
    "print(result_wide.head(6).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c39b2c37-0b6f-4212-8533-a0de0d599f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Merged on Date only.\n",
      "[OK] Saved → PPML_Gravity_Tariffs1.xlsx\n",
      "Rows: 108 | Columns: 41\n",
      "Tariff columns added: ['Agriculture_Imports_EuroM', 'Agriculture_SimpleAvg', 'Agriculture_WeightedAvg', 'Beverages_Imports_EuroM', 'Beverages_SimpleAvg', 'Beverages_WeightedAvg', 'Dairy_Imports_EuroM', 'Dairy_SimpleAvg', 'Dairy_WeightedAvg', 'Meat_Imports_EuroM'] …\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#File paths\n",
    "PPML_FILE = \"/Users/gouthamjekkula/Desktop/Thesis Folder/PPML_Gravity1.xlsx\"\n",
    "AHS_FILE  = \"/Users/gouthamjekkula/Desktop/Thesis Folder/Tariffs_2015_2023_Monthly_Sectors_Wide_AHS.xlsx\"\n",
    "OUT_FILE  = \"PPML_Gravity_Tariffs1.xlsx\"\n",
    "\n",
    "# 1) Read PPML_Gravity and normalize Date\n",
    "ppml = pd.read_excel(PPML_FILE)\n",
    "ppml.columns = [c.strip() for c in ppml.columns]\n",
    "if \"Date\" not in ppml.columns:\n",
    "    raise ValueError(\"PPML_Gravity.xlsx must contain a 'Date' column.\")\n",
    "ppml[\"Date\"] = pd.to_datetime(ppml[\"Date\"], errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# 2) Read AHS tariffs and normalize Date\n",
    "ahs = pd.read_excel(AHS_FILE)\n",
    "ahs.columns = [c.strip() for c in ahs.columns]\n",
    "if \"Date\" not in ahs.columns:\n",
    "    raise ValueError(\"Tariffs_2015_2023_Monthly_Sectors_Wide_AHS.xlsx must contain a 'Date' column.\")\n",
    "ahs[\"Date\"] = pd.to_datetime(ahs[\"Date\"], errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# 3) Identify tariff columns in the AHS file\n",
    "sector_prefixes = (\"Pharma_\", \"Agriculture_\", \"Beverages_\", \"Dairy_\", \"Meat_\", \"Vegetables_\")\n",
    "tariff_cols = [c for c in ahs.columns if c.startswith(sector_prefixes)]\n",
    "keep_ahs = [\"Date\"] + [c for c in ahs.columns if c in [\"Reporter Name\",\"Partner Name\"]] + tariff_cols\n",
    "ahs = ahs[keep_ahs].copy()\n",
    "\n",
    "# 4) If PPML already has old tariff columns, drop them to avoid duplicates\n",
    "old_tariff_cols = [c for c in ppml.columns if c.startswith(sector_prefixes)]\n",
    "if old_tariff_cols:\n",
    "    ppml = ppml.drop(columns=old_tariff_cols)\n",
    "\n",
    "# 5) Choose merge keys\n",
    "merge_keys = [\"Date\", \"Reporter Name\", \"Partner Name\"]\n",
    "can_merge_on_triplet = all(k in ppml.columns for k in merge_keys) and all(k in ahs.columns for k in merge_keys)\n",
    "\n",
    "if can_merge_on_triplet:\n",
    "    # align name fields\n",
    "    for k in [\"Reporter Name\",\"Partner Name\"]:\n",
    "        ppml[k] = ppml[k].astype(str).str.strip()\n",
    "        ahs[k]  = ahs[k].astype(str).str.strip()\n",
    "    merged = ppml.merge(ahs, on=merge_keys, how=\"left\")\n",
    "    print(\"[INFO] Merged on Date + Reporter Name + Partner Name.\")\n",
    "else:\n",
    "    merged = ppml.merge(ahs.drop(columns=[c for c in [\"Reporter Name\",\"Partner Name\"] if c in ahs.columns]),\n",
    "                        on=\"Date\", how=\"left\")\n",
    "    print(\"[INFO] Merged on Date only.\")\n",
    "\n",
    "# 6) Convert tariff columns to numeric and fill missing with 0\n",
    "if tariff_cols:\n",
    "    merged[tariff_cols] = merged[tariff_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "# 7) Save\n",
    "merged.to_excel(OUT_FILE, index=False)\n",
    "print(f\"[OK] Saved → {OUT_FILE}\")\n",
    "print(f\"Rows: {len(merged):,} | Columns: {len(merged.columns)}\")\n",
    "print(\"Tariff columns added:\", sorted(tariff_cols)[:10], \"…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6f5718a-ebfc-42dc-b303-f67f5f069c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved → PPML_clean_Dataset1.xlsx\n",
      "Rows: 125 | Columns: 67\n",
      "Sample tariff cols: ['Agriculture_SimpleAvg', 'Agriculture_WeightedAvg', 'Beverages_SimpleAvg', 'Beverages_WeightedAvg', 'Dairy_SimpleAvg', 'Dairy_WeightedAvg', 'Meat_SimpleAvg', 'Meat_WeightedAvg', 'Pharma_SimpleAvg', 'Pharma_WeightedAvg']\n",
      "Sample gravity cols: ['year', 'country_id_o', 'country_id_d', 'iso3_o', 'iso3_d', 'distw_harmonic', 'distw_arithmetic', 'dist', 'contig', 'comlang_off']\n",
      "First 15 columns: ['Date', 'Statistic Label', 'Country', 'UNIT', 'Agriculture', 'Agriculture_EuroM', 'Agriculture (%)', 'Beverages', 'Beverages_EuroM', 'Beverages (%)', 'Dairy', 'Dairy_EuroM', 'Dairy (%)', 'Meat', 'Meat_EuroM']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "EXPORT_FILE = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/Export_Master_Dataset_Clean.xlsx\")\n",
    "PPML_FILE   = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/PPML_Gravity_Tariffs1.xlsx\")\n",
    "OUT_FILE    = Path(\"PPML_clean_Dataset1.xlsx\")\n",
    "\n",
    " # 1) Export_Master (left table) — normalize Date and lock span\n",
    "exp = pd.read_excel(EXPORT_FILE)\n",
    "exp.columns = [c.strip() for c in exp.columns]\n",
    "if \"Date\" not in exp.columns:\n",
    "    raise ValueError(\"Export_Master_Dataset_Clean.xlsx must contain 'Date'.\")\n",
    "\n",
    "exp[\"Date\"] = pd.to_datetime(exp[\"Date\"], errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "date_min, date_max = exp[\"Date\"].min(), exp[\"Date\"].max()\n",
    "exp = exp[(exp[\"Date\"] >= date_min) & (exp[\"Date\"] <= date_max)].copy()\n",
    "\n",
    "# 2) PPML Gravity + Tariffs — normalize Date and trim to export span\n",
    "ppml = pd.read_excel(PPML_FILE)\n",
    "ppml.columns = [c.strip() for c in ppml.columns]\n",
    "if \"Date\" not in ppml.columns:\n",
    "    raise ValueError(\"PPML_Gravity_AHS_Tariffs.xlsx must contain 'Date'.\")\n",
    "\n",
    "ppml[\"Date\"] = pd.to_datetime(ppml[\"Date\"], errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "ppml = ppml[(ppml[\"Date\"] >= date_min) & (ppml[\"Date\"] <= date_max)].copy()\n",
    "\n",
    "# 3) Identify tariff vs gravity columns in PPML\n",
    "sector_prefixes = (\"Pharma_\", \"Agriculture_\", \"Beverages_\", \"Dairy_\", \"Meat_\", \"Vegetables_\")\n",
    "tariff_cols = [c for c in ppml.columns if c.startswith(sector_prefixes)]\n",
    "\n",
    "# gravity = everything else (except Date and the tariff cols)\n",
    "gravity_cols = [c for c in ppml.columns if c not in ([\"Date\"] + tariff_cols)]\n",
    "\n",
    "ppml_keep = ppml[[\"Date\"] + gravity_cols + tariff_cols].copy()\n",
    "\n",
    "# 4) Merge on Date (left join keeps export’s exact monthly span)\n",
    "merged = exp.merge(ppml_keep, on=\"Date\", how=\"left\", suffixes=(\"\", \"_ppmldup\"))\n",
    "\n",
    "# 5) Fill missing tariff columns with 0 (true pre‑Brexit & out-of-range months)\n",
    "if tariff_cols:\n",
    "    merged[tariff_cols] = merged[tariff_cols].fillna(0)\n",
    "\n",
    "# 6) Create Euro‑Millions versions of export value columns (inserted right after each original)\n",
    "#    These are in Euro Thousand in Export_Master\n",
    "export_value_cols = [\n",
    "    \"Agriculture\", \"Beverages\", \"Dairy\", \"Meat\", \"Pharmaceuticals\", \"Vegetables\", \"Other\",\n",
    "    \"6_Total_Exports_TSM09\", \"Total_Exports_All_commodities\"\n",
    "]\n",
    "export_value_cols = [c for c in export_value_cols if c in merged.columns]\n",
    "\n",
    "def insert_after(lst, after, new_item):\n",
    "    out = []\n",
    "    for x in lst:\n",
    "        out.append(x)\n",
    "        if x == after:\n",
    "            out.append(new_item)\n",
    "    return out\n",
    "\n",
    "# Build column order with EuroM right after originals\n",
    "col_order = merged.columns.tolist()\n",
    "for col in export_value_cols:\n",
    "    euro_col = f\"{col}_EuroM\"\n",
    "    merged[euro_col] = pd.to_numeric(merged[col], errors=\"coerce\") / 1000.0  # K€ -> €M\n",
    "    if euro_col not in col_order:\n",
    "        col_order = insert_after(col_order, col, euro_col)\n",
    "\n",
    "# 7) (Optional polish) Group sector triples: Value, EuroM, (%) if present\n",
    "sectors = [\"Agriculture\",\"Beverages\",\"Dairy\",\"Meat\",\"Pharmaceuticals\",\"Vegetables\",\"Other\"]\n",
    "meta_cols = [c for c in [\"Date\",\"Statistic Label\",\"Country\",\"UNIT\"] if c in merged.columns]\n",
    "\n",
    "grouped_sector_cols = []\n",
    "for s in sectors:\n",
    "    if s in merged.columns:\n",
    "        grouped_sector_cols.append(s)\n",
    "    if f\"{s}_EuroM\" in merged.columns:\n",
    "        grouped_sector_cols.append(f\"{s}_EuroM\")\n",
    "    if f\"{s} (%)\" in merged.columns:\n",
    "        grouped_sector_cols.append(f\"{s} (%)\")\n",
    "\n",
    "# totals\n",
    "grouped_totals = []\n",
    "for t in [\"6_Total_Exports_TSM09\",\"Total_Exports_All_commodities\"]:\n",
    "    if t in merged.columns:\n",
    "        grouped_totals.append(t)\n",
    "    if f\"{t}_EuroM\" in merged.columns:\n",
    "        grouped_totals.append(f\"{t}_EuroM\")\n",
    "\n",
    "# Arrange tariff blocks\n",
    "avg_cols    = sorted([c for c in tariff_cols if c.endswith(\"_WeightedAvg\") or c.endswith(\"_SimpleAvg\")])\n",
    "import_cols = sorted([c for c in tariff_cols if c.endswith(\"_Imports_EuroM\")])\n",
    "\n",
    "# Gravity block: keep original order of gravity_cols\n",
    "gravity_block = [c for c in gravity_cols if c in merged.columns]\n",
    "\n",
    "# Final order (add any leftovers at the end)\n",
    "ordered = []\n",
    "ordered += meta_cols\n",
    "ordered += grouped_sector_cols\n",
    "ordered += grouped_totals\n",
    "ordered += gravity_block\n",
    "ordered += avg_cols\n",
    "ordered += import_cols\n",
    "leftovers = [c for c in merged.columns if c not in ordered]\n",
    "ordered += leftovers\n",
    "\n",
    "merged = merged[ordered]\n",
    "\n",
    "# 8) Save\n",
    "merged.to_excel(OUT_FILE, index=False)\n",
    "print(f\"[OK] Saved → {OUT_FILE}\")\n",
    "print(f\"Rows: {len(merged):,} | Columns: {len(merged.columns)}\")\n",
    "print(\"Sample tariff cols:\", (avg_cols + import_cols)[:10])\n",
    "print(\"Sample gravity cols:\", gravity_block[:10])\n",
    "print(\"First 15 columns:\", merged.columns[:15].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d3f5d21-4a04-4b11-8b46-d945cc775917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved → PPML_clean_Dataset.xlsx\n",
      "Columns kept: 34\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "IN_FILE  = Path(\"/Users/gouthamjekkula/Desktop/Thesis Folder/PPML_clean_Dataset1.xlsx\")\n",
    "OUT_FILE = Path(\"PPML_clean_Dataset.xlsx\")\n",
    "\n",
    "# 1) Load \n",
    "df = pd.read_excel(IN_FILE)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "#2) Parse date & time_id \n",
    "if \"Date\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'Date' column.\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Date\"]).copy()\n",
    "if \"Year\" not in df.columns:\n",
    "    df[\"Year\"] = df[\"Date\"].dt.year\n",
    "if \"Month\" not in df.columns:\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month\n",
    "df[\"time_id\"] = df[\"Date\"].dt.to_period(\"M\").astype(str)  # e.g., '2019-07'\n",
    "\n",
    "# 3) Columns to DROP \n",
    "drop_cols = [\n",
    "    \"Statistic Label\", \"Country\", \"UNIT\",  # redundant text columns\n",
    "    \"Other_EuroM\"                          # out of thesis scope\n",
    "]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "#  4) Keep exactly what we need for PPML + Hybrid \n",
    "# Sectors (dependent variables)\n",
    "sectors = [\"Agriculture_EuroM\",\"Beverages_EuroM\",\"Dairy_EuroM\",\n",
    "           \"Meat_EuroM\",\"Pharmaceuticals_EuroM\",\"Vegetables_EuroM\"]\n",
    "\n",
    "# Gravity covariates\n",
    "gravity = [\n",
    "    \"GDP_IE_real_eur_m\",\"GDP_UK_real_eur_m\",\n",
    "    \"gdpcap_o\",\"gdpcap_d\",\"pop_o\",\"pop_d\",\n",
    "    \"distw_harmonic\",\"contig\",\"comlang_off\",\"comcol\",\"col45\",\n",
    "    \"rta_coverage\",\"rta_type\",\"iso3_d\"\n",
    "]\n",
    "\n",
    "# Tariffs (keep WeightedAvg + Imports_EuroM by sector)\n",
    "tariff_weighted = [\n",
    "    \"Agriculture_WeightedAvg\",\"Beverages_WeightedAvg\",\"Dairy_WeightedAvg\",\n",
    "    \"Meat_WeightedAvg\",\"Pharmaceuticals_WeightedAvg\",\"Vegetables_WeightedAvg\"\n",
    "]\n",
    "tariff_imports = [\n",
    "    \"Agriculture_Imports_EuroM\",\"Beverages_Imports_EuroM\",\"Dairy_Imports_EuroM\",\n",
    "    \"Meat_Imports_EuroM\",\"Pharmaceuticals_Imports_EuroM\",\"Vegetables_Imports_EuroM\"\n",
    "]\n",
    "\n",
    "# Time identifiers\n",
    "time_cols = [\"Date\",\"Year\",\"Month\",\"Period\",\"time_id\"]\n",
    "\n",
    "# Build final keep list (only columns that actually exist to avoid KeyErrors)\n",
    "final_keep = [c for c in (time_cols + sectors + gravity + tariff_weighted + tariff_imports) if c in df.columns]\n",
    "df_final = df[final_keep].copy()\n",
    "\n",
    "#sort for neatness\n",
    "df_final = df_final.sort_values([\"Date\"]).reset_index(drop=True)\n",
    "\n",
    "#5) Save modelling-ready dataset\n",
    "df_final.to_excel(OUT_FILE, index=False)\n",
    "print(f\"[OK] Saved → {OUT_FILE}\")\n",
    "print(\"Columns kept:\", len(df_final.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b68f93-8132-4f8b-b4d1-24e737f5cef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
